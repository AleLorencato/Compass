{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql.functions import rand, when, expr\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|             _c0|\n",
      "+----------------+\n",
      "|  Frances Bennet|\n",
      "|   Jamie Russell|\n",
      "|  Edward Kistler|\n",
      "|   Sheila Maurer|\n",
      "|Donald Golightly|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes.show(5)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             nome|\n",
      "+-----------------+\n",
      "|   Frances Bennet|\n",
      "|    Jamie Russell|\n",
      "|   Edward Kistler|\n",
      "|    Sheila Maurer|\n",
      "| Donald Golightly|\n",
      "|       David Gray|\n",
      "|      Joy Bennett|\n",
      "|      Paul Kriese|\n",
      "|Berniece Ornellas|\n",
      "|    Brian Farrell|\n",
      "+-----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- nome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")  \n",
    "\n",
    "df_nomes.show(10)\n",
    "\n",
    "df_nomes.printSchema()\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|             nome|Escolaridade|\n",
      "+-----------------+------------+\n",
      "|   Frances Bennet|       Medio|\n",
      "|    Jamie Russell|       Medio|\n",
      "|   Edward Kistler|       Medio|\n",
      "|    Sheila Maurer|    Superior|\n",
      "| Donald Golightly| Fundamental|\n",
      "|       David Gray|       Medio|\n",
      "|      Joy Bennett| Fundamental|\n",
      "|      Paul Kriese| Fundamental|\n",
      "|Berniece Ornellas| Fundamental|\n",
      "|    Brian Farrell|       Medio|\n",
      "+-----------------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- nome: string (nullable = true)\n",
      " |-- Escolaridade: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")  \n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 0.33, \"Fundamental\").when(rand() < 0.66, \"Medio\").otherwise(\"Superior\"))\n",
    "\n",
    "df_nomes.show(10)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+\n",
      "|             nome|     Pais|\n",
      "+-----------------+---------+\n",
      "|   Frances Bennet|  Uruguai|\n",
      "|    Jamie Russell|     Peru|\n",
      "|   Edward Kistler|    Chile|\n",
      "|    Sheila Maurer| Colombia|\n",
      "| Donald Golightly|    Chile|\n",
      "|       David Gray|    Chile|\n",
      "|      Joy Bennett|    Chile|\n",
      "|      Paul Kriese| Paraguai|\n",
      "|Berniece Ornellas|     Peru|\n",
      "|    Brian Farrell|   Brasil|\n",
      "|   Kara Mcelwaine|  Uruguai|\n",
      "|    Tracy Herring|    Chile|\n",
      "|  Howard Lazarine|Argentina|\n",
      "|     Leroy Strahl|   Brasil|\n",
      "|     Ernest Hulet| Paraguai|\n",
      "|     David Medina|    Chile|\n",
      "|   Lorenzo Woodis| Paraguai|\n",
      "|      Page Marthe| Paraguai|\n",
      "|   Herbert Morris|    Chile|\n",
      "|      Albert Leef|    Chile|\n",
      "|     Charles Hill|   Brasil|\n",
      "|  Helen Blackwell|  Uruguai|\n",
      "|          Lois Ly| Paraguai|\n",
      "|     Rebecca Snow|   Brasil|\n",
      "|      Frank Wiley|     Peru|\n",
      "| Wallace Mitchell|     Peru|\n",
      "|   Amanda Gravitt| Paraguai|\n",
      "|   Gabriel Colyer|   Brasil|\n",
      "|         Mary Lee|    Chile|\n",
      "|       Daryl Page| Colombia|\n",
      "+-----------------+---------+\n",
      "only showing top 30 rows\n",
      "\n",
      "root\n",
      " |-- nome: string (nullable = true)\n",
      " |-- Pais: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")  \n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 0.33, \"Fundamental\").when(rand() < 0.66, \"Medio\").otherwise(\"Superior\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Pais\", when(rand() < 0.077 , \"Brasil\").when(rand() < 0.154, \"Argentina\").when(rand() < 0.231, \"Chile\").when(rand() < 0.308, \"Uruguai\").when(rand() < 0.385, \"Paraguai\").when(rand() < 0.462, \"Peru\").when(rand() < 0.539, \"Colombia\").when(rand() < 0.616, \"Venezuela\").when(rand() < 0.693, \"Equador\").when(rand() < 0.770, \"Bolivia\").when(rand() < 0.847, \"Guiana\").when(rand() < 0.924, \"Suriname\").otherwise(\"França\"))\n",
    "\n",
    "df_nomes.show(30)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+--------------+\n",
      "|             nome|Escolaridade|ano_nascimento|\n",
      "+-----------------+------------+--------------+\n",
      "|   Frances Bennet|    Superior|          1965|\n",
      "|    Jamie Russell|       Medio|          1969|\n",
      "|   Edward Kistler|       Medio|          1973|\n",
      "|    Sheila Maurer|    Superior|          1955|\n",
      "| Donald Golightly|       Medio|          1961|\n",
      "|       David Gray| Fundamental|          1981|\n",
      "|      Joy Bennett|    Superior|          1992|\n",
      "|      Paul Kriese|       Medio|          1972|\n",
      "|Berniece Ornellas|    Superior|          2005|\n",
      "|    Brian Farrell| Fundamental|          1974|\n",
      "+-----------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- nome: string (nullable = true)\n",
      " |-- Escolaridade: string (nullable = false)\n",
      " |-- ano_nascimento: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 0.33, \"Fundamental\")\n",
    "                                             .when(rand() < 0.66, \"Medio\")\n",
    "                                             .otherwise(\"Superior\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"ano_nascimento\", (rand() * (2010 - 1945) + 1945).cast(\"int\"))\n",
    "\n",
    "df_nomes.show(10)\n",
    "\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+--------------+\n",
      "|             nome|Escolaridade|ano_nascimento|\n",
      "+-----------------+------------+--------------+\n",
      "| Donald Golightly| Fundamental|          2008|\n",
      "|Berniece Ornellas|       Medio|          2009|\n",
      "|   Lorenzo Woodis| Fundamental|          2005|\n",
      "|   Herbert Morris| Fundamental|          2009|\n",
      "|   Katrina Graham|    Superior|          2001|\n",
      "|      Lisa Baxley|    Superior|          2000|\n",
      "|    Milton Dillon| Fundamental|          2004|\n",
      "|    George Miller|    Superior|          2000|\n",
      "|        Ana Baker| Fundamental|          2001|\n",
      "|     Jerry Remick|    Superior|          2008|\n",
      "+-----------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 0.33, \"Fundamental\")\n",
    "                                             .when(rand() < 0.66, \"Medio\")\n",
    "                                             .otherwise(\"Superior\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"ano_nascimento\", (rand() * (2010 - 1945) + 1945).cast(\"int\"))\n",
    "\n",
    "df_select = df_nomes.filter(df_nomes.ano_nascimento >= 2000)\n",
    "\n",
    "df_select.show(10)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------+\n",
      "|            nome|Escolaridade|ano_nascimento|\n",
      "+----------------+------------+--------------+\n",
      "|        Mary Lee| Fundamental|          2007|\n",
      "|    Roxie Bernal| Fundamental|          2005|\n",
      "|   Milton Dillon|    Superior|          2007|\n",
      "|    Juliet Liles| Fundamental|          2000|\n",
      "|  Bernard Holmes| Fundamental|          2007|\n",
      "|    Jose Gaskins| Fundamental|          2002|\n",
      "|     Leola Hicks|    Superior|          2000|\n",
      "| Christine Frank|    Superior|          2001|\n",
      "|     Monica Earl|       Medio|          2000|\n",
      "|Gloria Archibald| Fundamental|          2004|\n",
      "+----------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 0.33, \"Fundamental\")\n",
    "                                             .when(rand() < 0.66, \"Medio\")\n",
    "                                             .otherwise(\"Superior\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"ano_nascimento\", (rand() * (2010 - 1945) + 1945).cast(\"int\"))\n",
    "\n",
    "df_select = df_nomes.createOrReplaceTempView(\"pessoas\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM pessoas WHERE ano_nascimento >= 2000\").show(10)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------+\n",
      "|            nome|Escolaridade|ano_nascimento|\n",
      "+----------------+------------+--------------+\n",
      "|   Sheila Maurer|    Superior|          1989|\n",
      "|Donald Golightly|       Medio|          1992|\n",
      "|   Brian Farrell| Fundamental|          1981|\n",
      "|   Tracy Herring| Fundamental|          1984|\n",
      "|     Albert Leef|    Superior|          1986|\n",
      "| Helen Blackwell| Fundamental|          1990|\n",
      "|      Daryl Page|       Medio|          1983|\n",
      "|    Roxie Bernal|       Medio|          1992|\n",
      "| Kenneth Rayburn| Fundamental|          1982|\n",
      "|      Anita Ross| Fundamental|          1981|\n",
      "+----------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 0.33, \"Fundamental\")\n",
    "                                             .when(rand() < 0.66, \"Medio\")\n",
    "                                             .otherwise(\"Superior\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"ano_nascimento\", (rand() * (2010 - 1945) + 1945).cast(\"int\"))\n",
    "\n",
    "df_select = df_nomes.filter(df_nomes['ano_nascimento'].between(1980, 1994))\n",
    "\n",
    "df_select.show(10)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+--------------+\n",
      "|           nome|Escolaridade|ano_nascimento|\n",
      "+---------------+------------+--------------+\n",
      "|  Jamie Russell|       Medio|          1990|\n",
      "|    Paul Kriese| Fundamental|          1993|\n",
      "|  Tracy Herring|       Medio|          1987|\n",
      "|   Leroy Strahl| Fundamental|          1994|\n",
      "| Lorenzo Woodis|    Superior|          1987|\n",
      "|   Charles Hill|       Medio|          1984|\n",
      "|        Lois Ly|       Medio|          1981|\n",
      "| Amanda Gravitt|       Medio|          1984|\n",
      "|Kenneth Rayburn|    Superior|          1984|\n",
      "|    Sandra Todd| Fundamental|          1990|\n",
      "+---------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 0.33, \"Fundamental\")\n",
    "                                             .when(rand() < 0.66, \"Medio\")\n",
    "                                             .otherwise(\"Superior\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"ano_nascimento\", (rand() * (2010 - 1945) + 1945).cast(\"int\"))\n",
    "\n",
    "df_select = df_nomes.createOrReplaceTempView(\"pessoas\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM pessoas WHERE ano_nascimento BETWEEN 1980 and 1994\").show(10)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+----------+\n",
      "|     pais|     geracao|quantidade|\n",
      "+---------+------------+----------+\n",
      "|Argentina|Baby Boomers|    438812|\n",
      "|Argentina|   Geração X|    328625|\n",
      "|Argentina|   Geração Z|    328016|\n",
      "|Argentina| Millennials|    327356|\n",
      "|  Bolivia|Baby Boomers|     17568|\n",
      "|  Bolivia|   Geração X|     13437|\n",
      "|  Bolivia|   Geração Z|     13179|\n",
      "|  Bolivia| Millennials|     13226|\n",
      "|   Brasil|Baby Boomers|    236257|\n",
      "|   Brasil|   Geração X|    177963|\n",
      "|   Brasil|   Geração Z|    178249|\n",
      "|   Brasil| Millennials|    178300|\n",
      "|    Chile|Baby Boomers|    554023|\n",
      "|    Chile|   Geração X|    415907|\n",
      "|    Chile|   Geração Z|    416175|\n",
      "|    Chile| Millennials|    417206|\n",
      "| Colombia|Baby Boomers|    228468|\n",
      "| Colombia|   Geração X|    171435|\n",
      "| Colombia|   Geração Z|    170760|\n",
      "| Colombia| Millennials|    170598|\n",
      "|  Equador|Baby Boomers|     51877|\n",
      "|  Equador|   Geração X|     39119|\n",
      "|  Equador|   Geração Z|     38898|\n",
      "|  Equador| Millennials|     38635|\n",
      "|   França|Baby Boomers|        66|\n",
      "|   França|   Geração X|        61|\n",
      "|   França|   Geração Z|        38|\n",
      "|   França| Millennials|        43|\n",
      "|   Guiana|Baby Boomers|      4428|\n",
      "|   Guiana|   Geração X|      3372|\n",
      "|   Guiana|   Geração Z|      3345|\n",
      "|   Guiana| Millennials|      3316|\n",
      "| Paraguai|Baby Boomers|    491033|\n",
      "| Paraguai|   Geração X|    370347|\n",
      "| Paraguai|   Geração Z|    369653|\n",
      "| Paraguai| Millennials|    369120|\n",
      "|     Peru|Baby Boomers|    363184|\n",
      "|     Peru|   Geração X|    272567|\n",
      "|     Peru|   Geração Z|    273023|\n",
      "|     Peru| Millennials|    272925|\n",
      "| Suriname|Baby Boomers|       764|\n",
      "| Suriname|   Geração X|       542|\n",
      "| Suriname|   Geração Z|       502|\n",
      "| Suriname| Millennials|       562|\n",
      "|  Uruguai|Baby Boomers|    569554|\n",
      "|  Uruguai|   Geração X|    425880|\n",
      "|  Uruguai|   Geração Z|    425740|\n",
      "|  Uruguai| Millennials|    427292|\n",
      "|Venezuela|Baby Boomers|    119695|\n",
      "|Venezuela|   Geração X|     89679|\n",
      "|Venezuela|   Geração Z|     89461|\n",
      "|Venezuela| Millennials|     89719|\n",
      "+---------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Ex3\").getOrCreate()\n",
    "\n",
    "df_nomes = spark.read.csv(\"../ex1-python/nomes_aleatorios.txt\")\n",
    "\n",
    "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"nome\")\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"Escolaridade\", when(rand() < 0.33, \"Fundamental\")\n",
    "                                             .when(rand() < 0.66, \"Medio\")\n",
    "                                             .otherwise(\"Superior\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"ano_nascimento\", (rand() * (2010 - 1945) + 1945).cast(\"int\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"pais\", when(rand() < 0.077 , \"Brasil\").when(rand() < 0.154, \"Argentina\").when(rand() < 0.231, \"Chile\").when(rand() < 0.308, \"Uruguai\").when(rand() < 0.385, \"Paraguai\").when(rand() < 0.462, \"Peru\").when(rand() < 0.539, \"Colombia\").when(rand() < 0.616, \"Venezuela\").when(rand() < 0.693, \"Equador\").when(rand() < 0.770, \"Bolivia\").when(rand() < 0.847, \"Guiana\").when(rand() < 0.924, \"Suriname\").otherwise(\"França\"))\n",
    "\n",
    "df_nomes = df_nomes.withColumn(\"geracao\", when(df_nomes.ano_nascimento.between(1944, 1964), \"Baby Boomers\").when(df_nomes.ano_nascimento.between(1965, 1979), \"Geração X\").when(df_nomes.ano_nascimento.between(1980, 1994), \"Millennials\").when(df_nomes.ano_nascimento.between(1995,2015),\"Geração Z\"))\n",
    "\n",
    "df_select = df_nomes.createOrReplaceTempView(\"pessoas\")\n",
    "\n",
    "spark.sql(\"SELECT pais, geracao, count(geracao) as quantidade FROM pessoas GROUP BY geracao,pais ORDER BY pais,geracao,quantidade\").show(100)\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
